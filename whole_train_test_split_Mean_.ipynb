{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 173 samples, Final_R is missing for the following sample\n",
    "137)\tMC\tair\t204\t8\t180\t60\t180\t500\t30\t114\t0.3\tNA\t150\t0.3\t100\t0.490196078\t486.395\t57.78712883\t26.00664167\t0.467\t9.68631173\t3\t0.422680412\t0.541775715\t0.521526486\t44.36424367"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-31 09:50:01.000317: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-31 09:50:01.659173: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/cuda/include:/usr/lib/cuda/lib64::/home/kianoosh/anaconda3/envs/tf/lib/\n",
      "2023-01-31 09:50:01.659239: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/cuda/include:/usr/lib/cuda/lib64::/home/kianoosh/anaconda3/envs/tf/lib/\n",
      "2023-01-31 09:50:01.659245: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# Import Python libaries\n",
    "%matplotlib inline\n",
    "from scipy.optimize import curve_fit\n",
    "import time as time\n",
    "# General data management\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib import rc, rcParams\n",
    "\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn import ensemble\n",
    "from xgboost import plot_tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "# import pydo\n",
    "# generate random integer values\n",
    "from random import seed\n",
    "from random import randint\n",
    "# seed random number generator\n",
    "seed(1)\n",
    "# Machine learning & model visualization tools\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, LeaveOneOut\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_gamma_deviance, mean_absolute_error\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from numpy import cov\n",
    "from scipy.stats import pearsonr\n",
    "from scipy import ndimage, misc\n",
    "\n",
    "from scipy import stats \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.externals import joblib\n",
    "# Miscellaneous\n",
    "import os\n",
    "import io\n",
    "import pydot\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras import backend as BK\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "#from sklearn.inspection import partial_dependence, plot_partial_dependence\n",
    "from progressbar import ProgressBar\n",
    "pbar = ProgressBar()\n",
    "\n",
    "glob_split = 4\n",
    "global_rand_state_xgb = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proxy properties\n",
    "# read the input data\n",
    "df = pd.read_csv('FJH_ML_Final_simulation_90rem.csv', header=1)\n",
    "df_dummy = pd.get_dummies(df)\n",
    "\n",
    "df['Norm_charge_tot'] = df['Charge_Tot']/(df['Mass'])*1000\n",
    "df['Norm_I_Max'] = df['I_Max']/df['Mass']*1000\n",
    "df['charge_density'] = df['Voltage']*df['Cap']/df['Mass']\n",
    "df['Final_Current_Percent'] = df['I_Final']/df['I_Max']\n",
    "\n",
    "Norm_I_Max = np.array (df['Norm_I_Max']).reshape(-1, 1)\n",
    "Final_Current_Percent  = np.array (df['Final_Current_Percent']).reshape(-1, 1)\n",
    "Norm_charge_tot  = np.array (df['Norm_charge_tot']).reshape(-1, 1)\n",
    "# final prediction, yield of Graphene\n",
    "df['Graphene_Yield'] = 100*df['Graphene_Yield']\n",
    "Graphene_Yield = np.array (df['Graphene_Yield']).reshape(-1, 1)\n",
    "\n",
    "Init_R = np.array (df['Init_R']).reshape (-1, 1)\n",
    "Res_Drop = np.array (df['Res_Drop']).reshape (-1, 1)\n",
    "Volt_Drop = np.array (df['Volt_Drop']).reshape (-1, 1)\n",
    "Mass = np.array (df['Mass']).reshape(-1, 1)\n",
    "\n",
    "# only process parameters that are in BO prediction\n",
    "Pretreat_voltage = np.array (df['Pretreat_voltage']).reshape(-1, 1)\n",
    "pulsetime = np.array (df['PulseTime']).reshape(-1, 1)\n",
    "charge_denisty = np.array (df['charge_density']).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type of material\n",
    "Material_CB = np.array (df_dummy['Material_CB']).reshape(-1, 1)\n",
    "Material_MC = np.array (df_dummy['Material_MC']).reshape(-1, 1) \n",
    "Material_PA = np.array (df_dummy['Material_PA']).reshape(-1, 1)\n",
    "Material_TCB = np.array (df_dummy['Material_TCB']).reshape(-1, 1)\n",
    "material_type = np.concatenate ((Material_CB, Material_MC, Material_PA, Material_TCB), axis=1)\n",
    "\n",
    "material_matrix = np.concatenate((np.array (df_dummy['Material_CB']).reshape([-1, 1]), \n",
    "                                  np.array (df_dummy['Material_MC']).reshape([-1, 1]),\n",
    "                                  np.array (df_dummy['Material_PA']).reshape([-1, 1]),\n",
    "                                  np.array (df_dummy['Material_TCB']).reshape([-1, 1])), axis=1)\n",
    "material_matrix = np.array (material_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# physical properties of precursor received from Kevin\n",
    "CB_ps_res_sa_sp2 = [45, 2.8, 1750, 41.2]\n",
    "MC_ps_res_sa_sp2 = [150, 0.4, 18, 45.9]\n",
    "PA_ps_res_sa_sp2 = [125, 7.2, 62, 42.4]\n",
    "TCB_ps_res_sa_sp2 = [106, 6.3, 74, 30.6]\n",
    "CB_MC_PA_TCB_ps_res_sa_sp2 = np.concatenate ([CB_ps_res_sa_sp2,\n",
    "                 MC_ps_res_sa_sp2,\n",
    "                 PA_ps_res_sa_sp2,\n",
    "                 TCB_ps_res_sa_sp2], axis=0).reshape(4,4)\n",
    "X_CB_MC_PA_TCB_ps_res_sa_sp2 = np.matmul(material_matrix, CB_MC_PA_TCB_ps_res_sa_sp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type of Atmosphere\n",
    "Atmosphere_air = np.array (df_dummy['Atmosphere_air']).reshape(-1, 1)\n",
    "Atmosphere_arg = np.array (df_dummy['Atmosphere_arg']).reshape(-1, 1)\n",
    "#Atmosphere_vac = np.array (df_dummy['Atmosphere_vac']).reshape(-1, 1)\n",
    "atmosphere_type = np.concatenate ((Atmosphere_air, Atmosphere_arg), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |#########################################################################|\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7290068366811557\n",
      "time is :  17719.952174663544\n"
     ]
    }
   ],
   "source": [
    "##########!!!!!!!!!!!!!!!!!!!!!!!! I reduced the n_estimators\n",
    "r_squareds_global = []\n",
    "list_glob_rand_state = []\n",
    "start = time.time()\n",
    "pbar = ProgressBar()\n",
    "# best split 2571, 2576\n",
    "repeat = 10000\n",
    "glob_split_list = np.repeat(range(2571, 2576), repeat)\n",
    "#If_rand_list = np.array (1000*np.round (np.random.rand(1, 5*repeat), 3), int).ravel()\n",
    "If_rand_list = np.array (1000*np.round (np.random.rand(1, 5*repeat), 3), int).ravel()\n",
    "Imax_rand_list = np.array (1000*np.round (np.random.rand(1, 5*repeat), 3), int).ravel()\n",
    "charge_rand_list = np.array (1000*np.round (np.random.rand(1, 5*repeat), 3), int).ravel()\n",
    "\n",
    "max_depths=[3, 3, 3, 3, 4]\n",
    "n_estimatorss=[28, 30, 22, 50, 35]\n",
    "gammas=[0.001, 0.001, 0.001, 0.001, 0.001,] \n",
    "learning_rates=[0.099383, 0.099383, 0.099383, 0.099383, 0.099383,] \n",
    "subsamples=[0.7746, 0.7746,  0.7746,  0.77,  0.7746, ] \n",
    "min_child_weights=[3, 3, 3, 3, 3]\n",
    "\n",
    "for glob_split, If_rand, Imax_rand, charge_rand in\\\n",
    "                     zip(pbar(glob_split_list), If_rand_list, Imax_rand_list, charge_rand_list):\n",
    "    #### Materials coef. for 3 time-current properties\n",
    "    #print ('#### material coef. for 3 current properties')\n",
    "    ## material coef. Final_Current_Percent\n",
    "    input_features = np.concatenate((material_matrix, charge_denisty, Init_R, \n",
    "                                     Res_Drop, Volt_Drop, Graphene_Yield), axis=1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "            input_features, Final_Current_Percent, test_size=0.2, random_state=glob_split)\n",
    "\n",
    "    clf = linear_model.LinearRegression()\n",
    "    clf = clf.fit(X_train, y_train.ravel())\n",
    "    CB_MC_PA_coef_Final_Current_Percent = clf.coef_[0: 4]\n",
    "    y_pred = clf.predict (X_test)\n",
    "    r2 = r2_score(y_test.ravel(), y_pred.ravel())\n",
    "    #print ('r2 mat_IfImax: ', r2)\n",
    "    pearr = pearsonr(y_test.ravel(), y_pred.ravel())\n",
    "    #print ('pearson r mat_IfImax: ', pearr[0])\n",
    "\n",
    "    ## material coef. I_max normalized\n",
    "    input_features = np.concatenate((material_matrix, Init_R, charge_denisty,\n",
    "                                     X_CB_MC_PA_TCB_ps_res_sa_sp2[:, (0, 1, 3)],\n",
    "                                     Res_Drop, Volt_Drop), axis=1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "            input_features, Norm_I_Max, test_size=0.2, random_state=glob_split)\n",
    "    clf = linear_model.LinearRegression()\n",
    "    clf = clf.fit(X_train, y_train.ravel())\n",
    "    CB_MC_PA_coef_Norm_I_Max = clf.coef_[0:4]\n",
    "    y_pred = clf.predict (X_test)\n",
    "    r2 = r2_score(y_test.ravel(), y_pred.ravel())\n",
    "    #print ('r2 mat_Imax: ', r2)\n",
    "    pearr = pearsonr(y_test.ravel(), y_pred.ravel())\n",
    "    #print ('pearson r mat_Imax: ', pearr[0])\n",
    "\n",
    "    ## material coef.  Norm_charge_tot\n",
    "    input_features = np.concatenate((material_matrix, Init_R, charge_denisty,\n",
    "                                     Res_Drop, Volt_Drop), axis=1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "            input_features, Norm_charge_tot, test_size=0.2, random_state=glob_split)\n",
    "    clf = linear_model.LinearRegression()\n",
    "    clf = clf.fit(X_train, y_train.ravel())\n",
    "    CB_MC_PA_coef_Norm_charge_tot = clf.coef_[0: 4]\n",
    "    y_pred = clf.predict (X_test)\n",
    "    r2 = r2_score(y_test.ravel(), y_pred.ravel())\n",
    "    #print ('r2 mat_chargetot: ', r2)\n",
    "    pearr = pearsonr(y_test.ravel(), y_pred.ravel())\n",
    "    #print ('pearson r mat_chargetot: ', pearr[0])\n",
    "    material_type_I_Finalperc_coef = material_type * CB_MC_PA_coef_Final_Current_Percent\n",
    "    material_type_Norm_I_Max_coef = material_type * CB_MC_PA_coef_Norm_I_Max\n",
    "    material_type_Norm_charge_Tot_coef = material_type * CB_MC_PA_coef_Norm_charge_tot\n",
    "\n",
    "    #### proxy XGBoost Final_Current_percent\n",
    "    new_features = np.concatenate ((charge_denisty, pulsetime,\n",
    "                                    material_type_I_Finalperc_coef,\n",
    "                                    atmosphere_type, Pretreat_voltage), axis=1)\n",
    "    indices = np.arange(len(new_features))\n",
    "    train_new_features, test_new_features, train_labels, test_labels, train_mat, test_mat, idxtrain, idx_test = \\\n",
    "                          train_test_split(new_features, Final_Current_Percent, df['Material'],\n",
    "                                         indices, test_size = 0.20, random_state = glob_split)\n",
    "    xgbr_final_I_percent = XGBRegressor(max_depth=3, n_estimators=20, gamma=0.001, \n",
    "                       learning_rate=0.0994, subsample=0.77, min_child_weight=9, n_jobs=1,\n",
    "                       random_state=If_rand)\n",
    "\n",
    "    xgbr_final_I_percent.fit(train_new_features, train_labels)\n",
    "    Final_Current_Percent_predicted = xgbr_final_I_percent.predict(new_features)  \n",
    "    y_pred = xgbr_final_I_percent.predict(test_new_features)\n",
    "    r_squared_Final_Current_test = r2_score(test_labels, y_pred)\n",
    "    #print('r2 score = ', r_squared_Final_Current_test)\n",
    "    pearsonr_Final_Current_test = pearsonr(test_labels.ravel(), y_pred.ravel())\n",
    "    #print('Pearson r for test samples= ', pearsonr_Final_Current_test[0])\n",
    "\n",
    "    #### proxy XGBoost Norm_I_Max\n",
    "    new_features = np.concatenate ((charge_denisty,\n",
    "                                    pulsetime, material_type_Norm_I_Max_coef,\n",
    "                                    atmosphere_type, Pretreat_voltage), axis=1)\n",
    "    indices = np.arange(len(new_features))\n",
    "    train_new_features, test_new_features, train_labels, test_labels, idxtrain, idx_test = \\\n",
    "                          train_test_split(new_features, Norm_I_Max, \n",
    "                                           indices, test_size = 0.2, random_state = glob_split)  \n",
    "    xgbr_norm_I_max = XGBRegressor(max_depth=5, n_estimators=35, gamma=0.001, \n",
    "                       learning_rate=0.09, subsample=0.775, min_child_weight=12, n_jobs=1,\n",
    "                      random_state=Imax_rand)\n",
    "    xgbr_norm_I_max.fit(train_new_features, train_labels);\n",
    "    Norm_I_Max_predicted = xgbr_norm_I_max.predict(new_features)\n",
    "    Norm_I_Max_test = xgbr_norm_I_max.predict(test_new_features)\n",
    "    r_squared_Norm_I_Max_test = r2_score(test_labels, Norm_I_Max_test)\n",
    "    #print('r2 score for test = ', r_squared_Norm_I_Max_test)\n",
    "    pr_Norm_I_Max_test = pearsonr(test_labels.ravel(), Norm_I_Max_test.ravel())\n",
    "    #print('pearson r for test= ', pr_Norm_I_Max_test[0])\n",
    "\n",
    "    #### proxy XGBoost Norm_Norm_charge_tot\n",
    "    #print ('#### proxy XGBoost Norm_Norm_charge_tot')\n",
    "    new_features = np.concatenate ((charge_denisty,pulsetime,\n",
    "                                    material_type_Norm_charge_Tot_coef,\n",
    "                                    atmosphere_type, Pretreat_voltage), axis=1)\n",
    "    indices = np.arange(len(new_features))\n",
    "    train_new_features, test_new_features, train_labels, test_labels, idxtrain, idx_test = \\\n",
    "                          train_test_split(new_features, Norm_charge_tot, \n",
    "                                           indices, test_size = 0.20, random_state = glob_split)\n",
    "    xgbr_norm_charge_total = XGBRegressor(max_depth=4, n_estimators=30, gamma=0.001, \n",
    "                   learning_rate=0.099395, subsample=0.75, min_child_weight=3, n_jobs=1,\n",
    "                  random_state=charge_rand)\n",
    "    xgbr_norm_charge_total.fit(train_new_features, train_labels)\n",
    "    Norm_charge_tot_predicted = xgbr_norm_charge_total.predict(new_features)\n",
    "    Norm_charge_tot_test = xgbr_norm_charge_total.predict(test_new_features)\n",
    "    r_squared_Norm_charge_tot_test = r2_score(test_labels, Norm_charge_tot_test)\n",
    "    #print('r2 score for test= ', r_squared_Norm_charge_tot_test)\n",
    "    pr_Norm_charge_tot_test = pearsonr(test_labels.ravel(), Norm_charge_tot_test.ravel())\n",
    "    #print('pearson r for test= ', pr_Norm_charge_tot_test[0])\n",
    "\n",
    "    #### FINAL prediction of Graphene Yield\n",
    "    CB_MC_PA_TCB_res = CB_MC_PA_TCB_ps_res_sa_sp2 [:, 1]\n",
    "    resistance_matrix = np.matmul(material_matrix, CB_MC_PA_TCB_res)\n",
    "    heat_power = np.array (df['Voltage']*df['Voltage']/(resistance_matrix**1)*df['PulseTime']*(1e-6)).reshape(-1, 1)\n",
    "    CB_MC_PA_TCB_coef_average = (CB_MC_PA_coef_Final_Current_Percent +\n",
    "                                 CB_MC_PA_coef_Norm_I_Max +\n",
    "                                 CB_MC_PA_coef_Norm_charge_tot)/3\n",
    "\n",
    "    material_type_GY_coef = material_type * CB_MC_PA_TCB_coef_average\n",
    "    new_features = np.concatenate ((charge_denisty, \n",
    "                                    X_CB_MC_PA_TCB_ps_res_sa_sp2,\n",
    "                                    #np.array(df['Volt_Drop']/df['I_Mean']).reshape(-1, 1),\n",
    "                                    #material_type_GY_coef,\n",
    "                                    pulsetime,\n",
    "                                    Pretreat_voltage,\n",
    "                                    np.log(np.array (df['temp2']).reshape(-1, 1)),\n",
    "\n",
    "                                    atmosphere_type,\n",
    "                                    Final_Current_Percent_predicted.reshape(-1, 1),\n",
    "                                    Norm_I_Max_predicted.reshape(-1, 1),\n",
    "                                    Norm_charge_tot_predicted.reshape(-1, 1), \n",
    "                                    heat_power.reshape(-1, 1)), axis=1)\n",
    "    test_size = 0.2\n",
    "    indices = np.arange(len(new_features))\n",
    "    labels = Graphene_Yield\n",
    "    train_new_features, test_new_features, train_labels, test_labels, idx_train, idx_test = \\\n",
    "                          train_test_split(new_features, labels, \n",
    "                                           indices, test_size = test_size, random_state=glob_split)\n",
    "    r_squareds = list()\n",
    "    r_squareds_randomized_testtrain = list()\n",
    "    r_squareds_train = list()\n",
    "    MAEs = list()\n",
    "    MAEs_train = list()\n",
    "    r2_max = 0\n",
    "    test_split_seed1 = glob_split\n",
    "    test_split_seed2 = glob_split + 1\n",
    "    test_split_count = test_split_seed2 - test_split_seed1\n",
    "    rep=10\n",
    "    r_squareds = list()\n",
    "    r_squareds_train = list()\n",
    "    MAEs = list()\n",
    "    MAEs_train = list()\n",
    "    # rand = 499 with max of:  0.79\n",
    "    for random_state in range (499, 500):\n",
    "        # Instantiate model with 1000 decision trees\n",
    "        xgbr_graphyield = XGBRegressor(max_depth=max_depths[glob_split-2571], \n",
    "                                       n_estimators=n_estimatorss[glob_split-2571], \n",
    "                                       gamma=gammas[glob_split-2571], \n",
    "                                       learning_rate=learning_rates[glob_split-2571], \n",
    "                                       subsample=subsamples[glob_split-2571],  \n",
    "                                       min_child_weight=min_child_weights[glob_split-2571], \n",
    "                                       n_jobs=1, random_state=random_state)\n",
    "        # Train the model on training data\n",
    "        xgbr_graphyield.fit(train_new_features, train_labels);\n",
    "        predictions = xgbr_graphyield.predict(test_new_features)\n",
    "        r_squared = r2_score(test_labels, predictions)\n",
    "        r_squareds.append (r_squared)\n",
    "    #m = tf.keras.metrics.RootMeanSquaredError()\n",
    "    pred_test = predictions\n",
    "    #m.update_state(pred_test, test_labels)\n",
    "    #print ('RMSE for test, ', m.result().numpy())\n",
    "    r_squareds_randomized_testtrain_vec = np.array ((r_squareds_randomized_testtrain))\n",
    "    #print ('all r2: ', r_squareds_randomized_testtrain_vec)\n",
    "    r_squareds_global.append(r_squareds)\n",
    "    list_glob_rand_state.append([glob_split, If_rand, Imax_rand, charge_rand])\n",
    "\n",
    "print (np.mean(r_squareds_global))\n",
    "end = time.time()\n",
    "print ('time is : ', end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7746"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsamples[glob_split-2571]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2571, 30, 470, 938]\n",
      "[2572, 881, 652, 515]\n",
      "[2573, 247, 374, 905]\n",
      "[2574, 314, 31, 746]\n",
      "[2575, 996, 405, 931]\n",
      "[0.8151036388943739]\n",
      "[0.798590987897155]\n",
      "[0.6729928053950183]\n",
      "[0.8352663225840645]\n",
      "[0.9047033546954542]\n",
      "0.8053314218932132\n"
     ]
    }
   ],
   "source": [
    "# modify the code based on your repeat variable\n",
    "one_2571 = np.argmax(r_squareds_global[0:repeat-1])\n",
    "two_2572 = repeat+np.argmax(r_squareds_global[repeat:2*repeat-1])\n",
    "three_2573 = 2*repeat+np.argmax(r_squareds_global[2*repeat:3*repeat-1])\n",
    "four_2574 = 3*repeat+np.argmax(r_squareds_global[3*repeat:4*repeat-1])\n",
    "five_2575 = 4*repeat+np.argmax(r_squareds_global[4*repeat:5*repeat-1])\n",
    "\n",
    "print (list_glob_rand_state[one_2571])\n",
    "print (list_glob_rand_state[two_2572])\n",
    "print (list_glob_rand_state[three_2573])\n",
    "print (list_glob_rand_state[four_2574])\n",
    "print (list_glob_rand_state[five_2575])\n",
    "\n",
    "print (r_squareds_global[one_2571])\n",
    "print (r_squareds_global[two_2572])\n",
    "print (r_squareds_global[three_2573])\n",
    "print (r_squareds_global[four_2574])\n",
    "print (r_squareds_global[five_2575])\n",
    "print (np.mean ( [r_squareds_global[one_2571],\n",
    " r_squareds_global[two_2572],\n",
    "\n",
    "                  r_squareds_global[three_2573],\n",
    " r_squareds_global[four_2574],\n",
    " r_squareds_global[five_2575]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8379134820129271\n",
      "[[2575, 946, 111, 212], [2575, 908, 363, 592], [2575, 443, 314, 999], [2575, 379, 733, 893], [2575, 292, 350, 70]]\n",
      "[[0.862629984501287], [0.8415907821807], [0.8373960190105182], [0.8188062627267404], [0.8291443616453904]]\n"
     ]
    }
   ],
   "source": [
    "sum = np.add.reduceat(r_squareds_global, np.arange(0, len(r_squareds_global), 5))\n",
    "argmax = np.argmax(sum)\n",
    "max = np.max(sum)\n",
    "print (np.mean ((r_squareds_global[5*argmax: 5*argmax+5])))\n",
    "print (list_glob_rand_state[5*argmax: 5*argmax+5])\n",
    "print (r_squareds_global[5*argmax: 5*argmax+5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22275"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7281277906079927"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean ((r_squareds_global[5*81: 5*81+5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3308105475094516"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum (([0.6858975863622747],\n",
    " [0.6800099640072237],\n",
    " [0.675616705108484],\n",
    " [0.5788779589672189],\n",
    " [0.7104083330642503]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = [1, 0, 0, 0, 0, 2, 0, 0, 0, 0]\n",
    "np.add.reduceat(c, np.arange(0, len(c), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.799800811194804],\n",
       " [0.7386401386407946],\n",
       " [0.6122911118428398],\n",
       " [0.8110958549485107],\n",
       " [0.8565695231640361],\n",
       " [0.7711356026258207],\n",
       " [0.6991659557860512],\n",
       " [0.5908010465628055],\n",
       " [0.8244761025364739],\n",
       " [0.8563341067248669]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_squareds_global[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_glob_rand_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2571, 211, 642, 196]\n",
      "[2572, 11, 373, 724]\n",
      "[2573, 298, 508, 794]\n",
      "[2574, 791, 795, 523]\n",
      "[2575, 946, 111, 212]\n",
      "[0.803339748844044]\n",
      "[0.7163432645322512]\n",
      "[0.5979997341571075]\n",
      "[0.8524998582085784]\n",
      "[0.862629984501287]\n",
      "0.7665625180486536\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to check what global random for training testing split is good:\n",
    "print ('mean of R2', np.mean(r_squareds_global))\n",
    "plt.subplots(figsize=(16, 4))\n",
    "#r_squareds_global_mean = np.mean (np.array (r_squareds_global), axis=0)\n",
    "r_squareds_global_mean = r_squareds_global\n",
    "plt.plot (list(range(len(r_squareds_global_mean))), \n",
    "             r_squareds_global_mean);\n",
    "xticks = list(range(0, len(r_squareds_global_mean), 1));\n",
    "plt.plot([0, len(r_squareds_global_mean)], \n",
    "         [np.mean(r_squareds_global_mean), \n",
    "          np.mean(r_squareds_global_mean)], color='red')\n",
    "plt.xticks(xticks, fontsize=7);\n",
    "plt.tight_layout()\n",
    "plt.savefig('randomrun.jpeg', dpi=500)\n",
    "# what random has the best average for the 5 runs\n",
    "print ('random of ', np.argmax (r_squareds_global_mean), \n",
    "       'with max of: ', np.max (r_squareds_global_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After fixing global randomness, check random of XGBoost\n",
    "print ('mean of R2', np.mean(r_squareds_global))\n",
    "plt.subplots(figsize=(16, 4))\n",
    "r_squareds_global_mean = np.mean (np.array (r_squareds_global), axis=0)\n",
    "plt.plot (list(range(len(r_squareds_global_mean))), \n",
    "             r_squareds_global_mean);\n",
    "xticks = list(range(0, len(r_squareds_global_mean), 1));\n",
    "plt.plot([0, len(r_squareds_global_mean)], \n",
    "         [np.mean(r_squareds_global_mean), \n",
    "          np.mean(r_squareds_global_mean)], color='red')\n",
    "plt.xticks(xticks, fontsize=7);\n",
    "plt.tight_layout()\n",
    "plt.savefig('randomrun.jpeg', dpi=500)\n",
    "# what random has the best average for the 5 runs\n",
    "print ('random of ', np.argmax (r_squareds_global_mean), \n",
    "       'with max of: ', np.max (r_squareds_global_mean))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
